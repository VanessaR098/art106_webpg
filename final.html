<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>Art 106 | Final Project</title>
  <link rel="stylesheet" type="text/css" href="main.css">
</head>

<body>

  <a href="index.html"> Home </a>
  <a href="a1.html"> Upgrade </a>
  <a href="a2.html"> Brushbot & LEDs </a>
  <a href="box.html">Micro Box</a>
  <a href="serial.html">Serial UI</a>
  <a href="prototype.html">Prototype</a>
  <a class="active" href="final.html"> Final </a>
  <a href="r1.html"> Reading #1 </a>
  <a href="r2.html"> Reading #2 </a>
  <a href="quiz.html">Quiz</a>

  <h1>Final Project</h1>

  <h3>Recap</h3>
  <p>My prototype of my project ended with my chassis robot being attached with a metro mini, stepper driver motors, 3 distance sensors, a graphic display, IMU, and neopixels. I currenly had a basic program that allowed all hardware parts to function unanimously, which also included some functions that allowed one part to affect another. In this program, my IMU controlled my neopixels, while displaying it's data on to the graphic display. My 3 distance sensors, when triggered at a specific distance, would cause the chassis bot to move forward. <br>(Refer back to "Prototype" page for more details) </p>

  <h3>Proposal A: Prototype Upgrade</h3>

  <p>The proposal I chose to accomplish for my final was <b>Proposal A: Prototype Upgrade.</b> The upgrades I plan to make are more software focused. These upgrades include:</p>
  <ul>
    <li>import an image on the graphic display to act as the bot's emotion --> graphic display will be triggered whenever the distance sensors detect something is too close to it</li>
    <dd>- images will mostly likely just be emotions --> (1) scared emotion when something is too close; (2) happy emotion when it's alone and not too close to anything</dd>
      <dd>- neopixels will also blink when distance sensors detect something is too close </dd>
    <li>IMU will act as a remote to control the chassis in real time --> if I move the IMU on the x-axis (at a certain interval since the IMU is very sensitive) the bot will move forward, if I tilt or move (I'm unsure which will would be better at the moment) the IMU to the right, the bot will turn right, and if I tilt/move the IMU left, the bot will turn left. </li>
    <li>have the graphic display display a right, left or forward arrow when the IMU is triggering a right, left or forward response to the chassis </li>
    <li>[aesthetics of my mouse bot to look like a mouse will be my last step depending on whether or not I will have enough time to do so (this is not the biggest priority)]</li>
  </ul>

  <h3>Hardware Parts (no changes made)</h3>
  <img src="Images/prototype.jpg" alt="Prototype" style="width:100%">
  <img src="Images/IMU.jpg" alt="Prototype(2)" style="width:37%">
  <img src="Images/IMU(2).jpg" alt="Prototype(3)" style="width:28%">
  <img src="Images/imu_extension.jpg" alt="Prototype(4)" style="width:34%">
  <img src="Images/distanceSensors.jpg" alt="Prototype(6)" style="width:48%">
  <img src="Images/distanceSensors(2).jpg" alt="Prototype(7)" style="width:49%">
  <img src="Images/neopixels.jpg" alt="Prototype(9)" style="width:40%; padding-left:100px">
  <img src="Images/display.jpg" alt="Prototype(8)" style="width:40%">
  <img src="Images/FinalDisplayOn.jpg" alt="Prototype(9)" style="width:40%; padding-left:100px">
  <img src="Images/FinalDisplayOn(2).jpg" alt="Prototype(9)" style="width:42%">



  <h3>Software Upgrades</h3>
  <div class="centerlink">
    <a href="Chassis_Bot_Prototype.txt" target="_blank"> Chassis_Bot_Prototype.txt</a>
  </div>
  <iframe src="https://player.vimeo.com/video/554433867?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="1100" height="700" style="padding-left:60px" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Final Bot"></iframe>

  <iframe src="https://player.vimeo.com/video/554460043?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" width="1100" height="700" style="padding-left: 60px" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen title="Final Bot (IMU)"></iframe>


  <h3>Success/Failures</h3>
  <p>My biggest success (although minimal) is getting the IMU to successfully move the robot by simply constraining the values of my IMU's axes. I'm also very happy that my neopixels and graphic display of emotions react accordingly and without delay to my distance sensors. For example, if any of the distance sensors are triggered, my graphic display will change from a happy/content emoji to a frightened emoji, and the neopixels will also all turn red to emphasize it's alarmed.  </p>
  <p>I definitely had several failures. One being I could not make office hours lol So this really made me fall behind as I would have questions, but I couldn't make office hours to ask them. So I had to figure out a simple method (that I could come up with lol) to achieve what I wanted and succesfully show progress of all my parts working how I intended them like in my proposals. One of my biggest failures was definitely not cleaning up my IMU's functionality more. Because I only merely constrained the values to be detected in that range and have my robot react only when that range is triggered, this lead to several sensitivity issues. Since the IMU is so sensitive, if the user is to move it in that range accidentally when making another gesture, it would trigger the robot to react differently than intended. Although I tested some if statements to try and clean this up, I just couldn't quite get it right.  Another failure was my front distance sensor not triggering my robot to go backwards. I researched and tried several different methods of trying to reverse my robot's DC motors, however only one motor would reverse so I decided to exclude this and just have both motors go forward for now when triggered by the front distance sensor :/ </p>
  </body>
